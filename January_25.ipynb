{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 5: Application Problem 1 - Optimal Asset Allocation/Consumption (Merton's 1969 Portfolio Problem)\n",
    "\n",
    "### OPTIMAL ASSET ALLOCATION IN DISCRETE TIME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (1) Formulate this problem as a Continuous States, Continuous Actions MDP by specifying itâ€™s State Transitions, Rewards and Discount Factor. The problem then is to find the Optimal Policy. **\n",
    "\n",
    "The dynamics of system is:\n",
    "$$W_{t+1} = (1 + r)(W_t - x_t) + (1 + R)x_t = (1 + r)W_t + S_t x_t$$\n",
    "The Rewards are zero for each period and the discount factor is $\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2) As always, we strive to find the Optimal Value Function. The first step in determining the Optimal Value Function is to write the Bellman Optimality Equation. **\n",
    "\n",
    "The Value function for each period is:\n",
    "$$V(t, W_t) = \\max_{x_t} \\gamma E \\left( V(t+1,W_{t+1}) \\right) = \\max_{x_t} \\gamma E \\left( V(t+1, (1 + r)W_t + S_t x_t) \\right)$$\n",
    "\n",
    "It can also be represented as:\n",
    "$$V(t,W_t) = \\gamma^{T-t} E \\{U(W_T)|W_t \\} = \\gamma^{T-t} E \\left(- \\frac { e ^ { - a W _ { T } } } { a }|W_t \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (3) Assume the functional form for the Optimal Value Function is $- b _ { t } e ^ { - c_t W _ { t } }$ where $b_t$, $c_t$ are unknowns functions of only $t$. Express the Bellman Optimality Equation using this functional form for the Optimal Value Function.**\n",
    "\n",
    "Use the Bellman equation from (2), we have:\n",
    "$$V(t,W_t) = \\max_{x_t} \\gamma E \\left( - b _ { t +1 } e ^ { - c_{t+1} W_{t+1}  } \\right) = \\max_{x_t} \\gamma E \\left( - b _ { t +1 } e ^ { - c_{t+1} ((1 + r)W_t + S_t x_t)  } \\right)$$\n",
    "Calculate the expecation by using the fact $S_t \\sim N(\\mu - r, \\sigma^2) $:\n",
    "$$\n",
    "V(t,W_t) = \\max_{x_t} \\int - \\gamma  b _ { t +1 } e ^ { - c_{t+1} ((1 + r)W_t + S_t x_t)  } \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^ {- \\frac{(S_t - (\\mu - r ))^2}{2 \\sigma^2}} d S_{t}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\max_{x_t} - \\frac{ \\gamma  b _ { t +1 } e^{- c_{t+1}(1+r)W_t }} {\\sqrt{2 \\pi \\sigma^2}} \\int e ^ {-c_{t+1} x_t S_t - \\frac{(S_t - (\\mu - r ))^2}{2 \\sigma^2}} d S_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\max_{x_t} - \\gamma  b _ { t +1 } e^{- c_{t+1}(1+r)W_t } e ^{\\frac{1}{2} \\sigma^2 c_{t+1} x_t^2 - (\\mu - r)c_{t+1} x_t}\n",
    "$$\n",
    "$$\n",
    "= \\max_{x_t} - \\gamma \\cdot b _ { t + 1 } e ^ { - c _ { t + 1 } W _ { t } ( 1 + r ) - c _ { t + 1 } x _ { t } ( \\mu - r ) + \\frac { \\sigma ^ { 2 } } { 2 } c _ { t + 1 } ^ { 2 } x _ { t } ^ { 2 } }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (4) Since the right-hand-side of the Bellman Optimality Equation involves a max over $x_t$, we can say that the partial derivative of the term inside the max with respect to $x_t$ is 0. This enables us to write the Optimal Allocation\n",
    "$x_t^*$ in terms of $c_{t+1}$ . **\n",
    "\n",
    "Take the derivative of the value function over $x_t$:\n",
    "\n",
    "$$\n",
    " \\max_{x_t} - \\gamma b_{t+1} e ^{(\\dots)} \\left( -  c_{t+1}(\\mu - r) + \\sigma^2 c_{t+1}^2 x_t^* \\right) = 0\n",
    "$$\n",
    "\n",
    "Therefore, we have:\n",
    "$$\n",
    "x_t^* = \\frac{\\mu - r}{\\sigma^2 c_{t+1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5) Substituting this maximizing $x_t^*$ in the Bellman Optimality Equation enables us to express $b_t$ and $c_t$ as recursive equations in terms of $b_{t+1}$ and $c_{t+1}$ respectively.\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V(t, W_t) = - \\gamma \\cdot b _ { t + 1 } e ^ { - c _ { t + 1 } W _ { t } ( 1 + r ) - \\frac{(\\mu - r)^2}{2 \\sigma^2} } = - \\gamma \\cdot b _ { t + 1 } e^{- \\frac{(\\mu - r)^2}{2 \\sigma^2}} e ^ { - c _ { t + 1 } W _ { t } ( 1 + r )}\n",
    "$$\n",
    "Therefore, we have:\n",
    "$$\n",
    "b_t = \\gamma \\cdot b _ { t + 1 } e^{- \\frac{(\\mu - r)^2}{2 \\sigma^2} } \n",
    "$$\n",
    "$$\n",
    "c_t = c_{t + 1}( 1 + r )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6) We know $b_T$ and $c_T$ from the knowledge of the MDP Reward at $t = T$ (Utility of Terminal Wealth), which enables us to unroll the above recursions for $b_t$ and $c_t$.**\n",
    "\n",
    "As we have $V_T(W_T) = - \\frac{e^{-a W_T}}{a}$, we know:\n",
    "$$\n",
    "b_T = \\frac{1}{a}\n",
    "$$\n",
    "$$\n",
    "c_T = a\n",
    "$$\n",
    "\n",
    "Then solve $b_t$ and $c_t$ recursively:\n",
    "$$\n",
    "b _ { t } = \\frac { \\gamma ^ { T - t } } { a } e ^ { - \\frac { ( \\mu - r ) ^ { 2 } \\cdot ( T - t ) } { 2 \\sigma ^ { 2 } } }\n",
    "$$\n",
    "$$\n",
    "c _ { t } = a \\cdot ( 1 + r ) ^ { T - t }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(7) Solving $b_t$ and $c_t$ yields the Optimal Policy and the Optimal Value Function. **\n",
    "$$\n",
    "x_t^* = \\frac{\\mu - r}{\\sigma^2 c_{t+1}} = \\frac{\\mu - r}{\\sigma^2 a  (1 + r)^{T - t - 1}}\n",
    "$$\n",
    "$$\n",
    "V(t,W_t) =   - \\gamma \\cdot b _ { t + 1 } e^{- \\frac{(\\mu - r)^2}{2 \\sigma^2}} e ^ { - c _ { t + 1 } W _ { t } ( 1 + r )} =  - \\gamma \\cdot  \\frac { \\gamma ^ { T - t - 1 } } { a } e ^ { - \\frac { ( \\mu - r ) ^ { 2 } \\cdot ( T - t -1) } { 2 \\sigma ^ { 2 } } } e^{- \\frac{(\\mu - r)^2}{2 \\sigma^2}} e ^ { - a \\cdot ( 1 + r ) ^ { T - t - 1} W _ { t } ( 1 + r )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V(t, W_t) = - \\frac{\\gamma^{T -t}}{a} e^{- \\frac{(\\mu - r)^2(T-t)}{2 \\sigma^2} - a (1+r)^{T-t}W_t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
