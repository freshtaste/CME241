{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1: Markov Processes (MP) and Markov Reward Processes (MRP)\n",
    "\n",
    "### MP definition\n",
    "**Markov Process**: a MP is a tuple ($S$, $P$), such that $S$ is a finite set of states and $P$ is a state transition probability matrix, $P_{ss'} = Pr[S_{t+1} = s'|S_t =s]$.\n",
    "\n",
    "**Example: Student Markov Chain**: \n",
    "\n",
    "The state space is $S = \\{Class1, Class2, Class3, Facebook, Pub, Pass, Sleep\\}$. \n",
    "\n",
    "\\begin{equation*}\n",
    "P_{ss'} = \n",
    "\\begin{bmatrix}\n",
    "0 & 0.5 & 0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0.8 & 0 & 0 & 0 & 0.2 \\\\\n",
    "0 & 0 & 0 & 0 & 0.4 & 0.6 & 0 \\\\\n",
    "0.1 & 0 & 0 & 0.9 & 0 & 0 & 0 \\\\\n",
    "0.2 & 0.4 & 0.4 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Python code representation of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = \n",
      "[[0.  0.5 0.  0.5 0.  0.  0. ]\n",
      " [0.  0.  0.8 0.  0.  0.  0.2]\n",
      " [0.  0.  0.  0.  0.4 0.6 0. ]\n",
      " [0.1 0.  0.  0.9 0.  0.  0. ]\n",
      " [0.2 0.4 0.4 0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "S = ['Class1','Class2','Class3','Facebook','Pub','Pass','Sleep']\n",
    "P = np.zeros((len(S),len(S)))\n",
    "P[0,1] = 0.5\n",
    "P[0,3] = 0.5\n",
    "P[1,2] = 0.8\n",
    "P[1,6] = 0.2\n",
    "P[2,4] = 0.4\n",
    "P[2,5] = 0.6\n",
    "P[3,0] = 0.1\n",
    "P[3,3] = 0.9\n",
    "P[4,0] = 0.2\n",
    "P[4,1] = 0.4\n",
    "P[4,2] = 0.4\n",
    "P[5,6] = 1\n",
    "print(\"P = \")\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRP definition\n",
    "**Markov Reward Process**: MRP is a Markov chain with values, which can be represented as a tuple ($S$, $P$, $R$, $\\gamma$). In addition to MP, $R$ is a reward function, $R_s = \\mathbb{E}[R_{t+1}| S_t = s]$. $\\gamma$ is a discount factor, $\\gamma \\in [0,1]$.\n",
    "\n",
    "\\begin{equation*}\n",
    "R_{s} = \n",
    "\\begin{bmatrix}\n",
    "-2\\\\\n",
    "-2\\\\\n",
    "-2\\\\\n",
    "-1\\\\\n",
    "+1\\\\\n",
    "+10\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Python code representation of the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = \n",
      "[-2 -2 -2 -1  1 10  0]\n"
     ]
    }
   ],
   "source": [
    "R = np.array([-2,-2,-2,-1,+1,+10,0])\n",
    "print('R = ')\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
