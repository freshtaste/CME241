{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 12: Policy Gradient Algorithms\n",
    "### 1. Proof of the Policy Gradient Theorem\n",
    "**(1) Policy Gradient Theorem: **\n",
    "$$\n",
    "\\nabla_{\\theta} J(\\theta)=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi(s, a ; \\theta) \\cdot Q^{\\pi}(s, a) \\cdot d a \\cdot d s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) Proof: **\n",
    "\n",
    "We begin the proof by noting that:\n",
    "$$\n",
    "J(\\theta)=\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\cdot V^{\\pi}\\left(s_{0}\\right) \\cdot d s_{0}=\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot Q^{\\pi}\\left(s_{0}, a_{0}\\right) \\cdot d a_{0} \\cdot d s_{0}\n",
    "$$\n",
    "Calculate $\\nabla_{\\theta} J(\\theta)$ by parts:\n",
    "$$\n",
    "\\begin{aligned} \\nabla_{\\theta} J(\\theta) &=\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot Q^{\\pi}\\left(s_{0}, a_{0}\\right) \\cdot d a_{0} \\cdot d s_{0} \\\\ &+\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot \\nabla_{\\theta} Q^{\\pi}\\left(s_{0}, a_{0}\\right) \\cdot d a_{0} \\cdot d s_{0} \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now bring the $\\nabla_{\\theta}$ inside the $\\int_{\\mathcal{S}}$ to apply only on $V^{\\pi}\\left(s_{1}\\right)$:\n",
    "$$\n",
    "\\begin{array}{l}{=\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot Q^{\\pi}\\left(s_{0}, a\\right) \\cdot d a_{0} \\cdot d s_{0}} \\\\ {+\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\int_{\\mathcal{S}} \\gamma \\cdot \\mathcal{P}_{s, s_{1}}^{a_{0}} \\cdot \\nabla_{\\theta} V^{\\pi}\\left(s_{1}\\right) \\cdot d s_{1} \\cdot d a_{0} \\cdot d s_{0}}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now bring the outside $\\int_{\\mathcal{S}}$ and $\\int_{\\mathcal{A}}$ inside the inner $\\int_{\\mathcal{S}}$\n",
    "$$\n",
    "\\begin{array}{l}{=\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot Q^{\\pi}\\left(s_{0}, a_{0}\\right) \\cdot d a_{0} \\cdot d s_{0}} \\\\ {+\\int_{\\mathcal{S}}\\left(\\int_{\\mathcal{S}} \\gamma \\cdot p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot \\mathcal{P}_{s_{0}, s_{1}}^{a_{0}} \\cdot d a_{0} \\cdot d s_{0}\\right) \\cdot \\nabla_{\\theta} V^{\\pi}\\left(s_{1}\\right) \\cdot d s_{1}}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now back to when we started calculating gradient of $\\int_{\\mathcal{A}} \\pi \\cdot Q^{\\pi} \\cdot d a$. Follow the same process of splitting $\\pi \\cdot Q^{\\pi}$, then Bellman-expanding $Q^{\\pi}$ (to calculate its gradient), and iterate.\n",
    "$$\n",
    "\\begin{array}{l}{=\\int_{\\mathcal{S}} p_{0}\\left(s_{0}\\right) \\int_{\\mathcal{A}} \\cdot \\nabla_{\\theta} \\pi\\left(s_{0}, a_{0} ; \\theta\\right) \\cdot Q^{\\pi}\\left(s_{0}, a_{0}\\right) \\cdot d a_{0} \\cdot d s_{0}} \\\\ {+\\int_{\\mathcal{S}} \\int_{\\mathcal{S}} \\gamma p_{0}\\left(s_{0}\\right) p\\left(s_{0} \\rightarrow s_{1}, 1, \\pi\\right) d s_{0}\\left(\\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi\\left(s_{1}, a_{1} ; \\theta\\right) Q^{\\pi}\\left(s_{1}, a_{1}\\right) d a_{1}+\\ldots\\right) d s_{1}}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iterative process leads us to:\n",
    "$$\n",
    "=\\sum_{t=0}^{\\infty} \\int_{\\mathcal{S}} \\int_{\\mathcal{S}} \\gamma^{t} \\cdot p_{0}\\left(s_{0}\\right) \\cdot p\\left(s_{0} \\rightarrow s_{t}, t, \\pi\\right) \\cdot d s_{0} \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi\\left(s_{t}, a_{t} ; \\theta\\right) \\cdot Q^{\\pi}\\left(s_{t}, a_{t}\\right) \\cdot d a_{t} \\cdot d s_{t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring $\\sum_{t=0}^{\\infty}$ inside the two integration\n",
    "$$\n",
    "=\\int_{\\mathcal{S}} \\int_{\\mathcal{S}} \\sum_{t=0}^{\\infty} \\gamma^{t} \\cdot p_{0}\\left(s_{0}\\right) \\cdot p\\left(s_{0} \\rightarrow s, t, \\pi\\right) \\cdot d s_{0} \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi(s, a ; \\theta) \\cdot Q^{\\pi}(s, a) \\cdot d a \\cdot d s\n",
    "$$\n",
    "Remind that $\\int_{\\mathcal{S}} \\sum_{t=0}^{\\infty} \\gamma^{t} \\cdot p_{0}\\left(s_{0}\\right) \\cdot p\\left(s_{0} \\rightarrow s, t, \\pi\\right) \\cdot d s_{0} \\stackrel{\\mathrm{def}}{=} \\rho^{\\pi}(s)$. So\n",
    "$$\n",
    "\\begin{array}{c}{\\nabla_{\\theta} J(\\theta)=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi(s, a ; \\theta) \\cdot Q^{\\pi}(s, a) \\cdot d a \\cdot d s} \\\\ {\\mathbb{Q} \\cdot \\mathbb{E} . \\mathbb{D}}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Score function for softmax policy\n",
    "$$\n",
    "\\pi(s, a ; \\theta)=\\frac{e^{\\theta^{T} \\cdot \\phi(s, a)}}{\\sum_{b} e^{\\theta^{T} \\cdot \\phi(s, b)}} \\text { for all } s \\in \\mathcal{S}, a \\in \\mathcal{A}\n",
    "$$\n",
    "$$\n",
    "\\nabla_{\\theta} \\log \\pi(s, a ; \\theta)=\\phi(s, a)-\\sum_{b} \\pi(s, b ; \\theta) \\cdot \\phi(s, b)=\\phi(s, a)-\\mathbb{E}_{\\pi}[\\phi(s, \\cdot)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Score function for gaussian policy\n",
    "$$\n",
    "\\nabla_{\\theta} \\log \\pi(s, a ; \\theta)=\\frac{\\left(a-\\theta^{T} \\cdot \\phi(s)\\right) \\cdot \\phi(s)}{\\sigma^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write Proof of the Compatible Function Approximation Theorem\n",
    "**1. Two conditions: **\n",
    "\n",
    "Critic gradient is compatible with the Actor score function\n",
    "$$\n",
    "\\nabla_{w} Q(s, a ; w)=\\nabla_{\\theta} \\log \\pi(s, a ; \\theta)\n",
    "$$\n",
    "Critic parameters w minimize the following mean-squared error:\n",
    "$$\n",
    "\\epsilon=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta)\\left(Q^{\\pi}(s, a)-Q(s, a ; w)\\right)^{2} \\cdot d a \\cdot d s\n",
    "$$\n",
    "Then the Policy Gradient using critic is exact:\n",
    "$$\n",
    "\\nabla_{\\theta} J(\\theta)=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi(s, a ; \\theta) \\cdot Q(s, a ; w) \\cdot d a \\cdot d s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Proof of the theorem: **\n",
    "\n",
    "For $w$ that minimizes\n",
    "$$\n",
    "\\begin{array}{c}{\\epsilon=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot\\left(Q^{\\pi}(s, a)-Q(s, a ; w)\\right)^{2} \\cdot d a \\cdot d s} \\\\ {\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot\\left(Q^{\\pi}(s, a)-Q(s, a ; w)\\right) \\cdot \\nabla_{w} Q(s, a ; w) \\cdot d a \\cdot d s=0}\\end{array}\n",
    "$$\n",
    "But since $\\nabla_{w} Q(s, a ; w)=\\nabla_{\\theta} \\log \\pi(s, a ; \\theta)$, we have\n",
    "$$\n",
    "\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot\\left(Q^{\\pi}(s, a)-Q(s, a ; w)\\right) \\cdot \\nabla_{\\theta} \\log \\pi(s, a ; \\theta) \\cdot d a \\cdot d s=0\n",
    "$$\n",
    "Therefore,\n",
    "$$\n",
    "\\begin{array}{c}{\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot Q^{\\pi}(s, a) \\cdot \\nabla_{\\theta} \\log \\pi(s, a ; \\theta) \\cdot d a \\cdot d s} \\\\ {=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot Q(s, a ; w) \\cdot \\nabla_{\\theta} \\log \\pi(s, a ; \\theta) \\cdot d a \\cdot d s}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\operatorname{But} \\nabla_{\\theta} J(\\theta)=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot Q^{\\pi}(s, a) \\cdot \\nabla_{\\theta} \\log \\pi(s, a ; \\theta) \\cdot d a \\cdot d s\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned} \\text { So, } \\nabla_{\\theta} J(\\theta) &=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\pi(s, a ; \\theta) \\cdot Q(s, a ; w) \\cdot \\nabla_{\\theta} \\log \\pi(s, a ; \\theta) \\cdot d a \\cdot d s \\\\ &=\\int_{\\mathcal{S}} \\rho^{\\pi}(s) \\int_{\\mathcal{A}} \\nabla_{\\theta} \\pi(s, a ; \\theta) \\cdot Q(s, a ; w) \\cdot d a \\cdot d s \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
