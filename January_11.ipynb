{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1: Markov Processes (MP) and Markov Reward Processes (MRP)\n",
    "\n",
    "### MP definition\n",
    "**Markov Process**: a MP is a tuple ($S$, $P$), such that $S$ is a finite set of states and $P$ is a state transition probability matrix, $P_{ss'} = Pr[S_{t+1} = s'|S_t =s]$.\n",
    "\n",
    "**Example: Student Markov Chain**: \n",
    "\n",
    "The state space is $S = \\{Class1, Class2, Class3, Facebook, Pub, Pass, Sleep\\}$. \n",
    "\n",
    "\\begin{equation*}\n",
    "P_{ss'} = \n",
    "\\begin{bmatrix}\n",
    "0 & 0.5 & 0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0.8 & 0 & 0 & 0 & 0.2 \\\\\n",
    "0 & 0 & 0 & 0 & 0.4 & 0.6 & 0 \\\\\n",
    "0.1 & 0 & 0 & 0.9 & 0 & 0 & 0 \\\\\n",
    "0.2 & 0.4 & 0.4 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "### Class design for MP\n",
    "**Design:**\n",
    "1. Data structure: The data type of MP processes is a dictionary with its values defined as another dictionary, which describes the states and the transition matrix.\n",
    "2. Stationary distribution: Calculate $\\pi$ with $\\pi = \\pi P$.\n",
    "\n",
    "**Example:**\n",
    "\\begin{equation*}\n",
    "P_{ss'} = \n",
    "\\begin{bmatrix}\n",
    "0.1 & 0.6 & 0.1 & 0.2 \\\\\n",
    "0.25 & 0.22 & 0.24 & 0.29 \\\\\n",
    "0.7 & 0.3 & 0 & 0 \\\\\n",
    "0.3 & 0.5 & 0.2 & 0  \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[[0.1  0.6  0.1  0.2 ]\n",
      " [0.25 0.22 0.24 0.29]\n",
      " [0.7  0.3  0.   0.  ]\n",
      " [0.3  0.5  0.2  0.  ]]\n",
      "{1: 0.28574421284173046, 2: 0.38860374986906865, 3: 0.15580810725882485, 4: 0.16984393003037593}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liujizhou/Desktop/MS&E346/cme241/CME241/src/mp.py:29: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ).astype(float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.mp import MP\n",
    "\n",
    "transitions = {\n",
    "        1: {1: 0.1, 2: 0.6, 3: 0.1, 4: 0.2},\n",
    "        2: {1: 0.25, 2: 0.22, 3: 0.24, 4: 0.29},\n",
    "        3: {1: 0.7, 2: 0.3},\n",
    "        4: {1: 0.3, 2: 0.5, 3: 0.2}\n",
    "    }\n",
    "\n",
    "mp_obj = MP(transitions)\n",
    "print(mp_obj.all_state_list)\n",
    "print(mp_obj.get_tran_mat())\n",
    "stationary = mp_obj.stationary_distribution()\n",
    "print(stationary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRP definition\n",
    "**Markov Reward Process**: MRP is a Markov chain with values, which can be represented as a tuple ($S$, $P$, $R$, $\\gamma$). In addition to MP, $R$ is a reward function, $R_s = \\mathbb{E}[R_{t+1}| S_t = s]$. $\\gamma$ is a discount factor, $\\gamma \\in [0,1]$.\n",
    "\n",
    "\\begin{equation*}\n",
    "R_{s} = \n",
    "\\begin{bmatrix}\n",
    "-2\\\\\n",
    "-2\\\\\n",
    "-2\\\\\n",
    "-1\\\\\n",
    "+1\\\\\n",
    "+10\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "### Class design for MRP\n",
    "**Design:**\n",
    "1. Data structure: MRP is a subclass of MP with two additional inputs: rewards and discout factors. The reward is a dictionary that maps states to the value fo reward.\n",
    "2. Converting between two different definitions: the $r(s,s')$ and the $R(s) = \\sum_{s'} p(s,s') * r(s,s')$.\n",
    "\n",
    "Code Design for First definiton of MRP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n",
      "[[0.6 0.3]\n",
      " [0.1 0.2]]\n",
      "[29.65517241 16.20689655]\n"
     ]
    }
   ],
   "source": [
    "from src.mrp import MRP\n",
    "\n",
    "transitions = {\n",
    "        1: {1: 0.6, 2: 0.3, 3: 0.1}, \n",
    "        2: {1: 0.1, 2: 0.2, 3: 0.7},\n",
    "        3: {3: 1.0}\n",
    "    }\n",
    "reward = {1: 7.0, 2:10.0, 3:0.0}\n",
    "gamma = 1.0\n",
    "mrp_obj = MRP(transitions, reward, gamma)\n",
    "print(mrp_obj.get_states())\n",
    "print(mrp_obj.get_trans_matrix())\n",
    "print(mrp_obj.valueFun())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Design for Second definiton of MRP:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
